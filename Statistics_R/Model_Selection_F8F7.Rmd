---
title: "Regression Model Selection (F8-F7)"
output: html_notebook
---
```{r}
# LOAD REQUIRED PACKAGES
library(readxl)
library(car)

# Import data
datadir <- "D:\\MPI_LEMON\\EEG_MPILMBB_LEMON\\EEG_Statistics\\DataLemon.xlsx" # Path to dataLemon
Data <- data.frame(read_excel(datadir, 1, col_names = TRUE))
row.names(Data) <- Data[,1] # set row names
Data <- Data[,-1] # delete subject variable
Data[,19] <- factor(Data[,19]) # make categorical variables into factors
Data[,20] <- factor(Data[,20])
Data[,21] <- factor(Data[,21])

# Create separate datasets for each model, without missing values
na.ham <- which(is.na(Data$Hamilton.Scale)) # find two missing values in Hamilton.Scale
na.skid <- which(is.na(Data$SKID.Diagnoses)) # find one missing value in SKID.Diagnoses
na <- c(na.ham, na.skid) # combine three missing values
Data.no.na <- Data[-na, ] # remove those 3 subjects as they cannot be entered into regression
dataF8F7 <- Data.no.na[,-c(1:3)]
N = nrow(dataF8F7)
```
## Model Selectrion for (F8-F7)

The aim is to build a linear model for predicting and explaining FAA (F4-F3)
The stepwise model selection sequentially compares multiple linear regression models with different predictors, improving a performance measure, in the form of an information criterion, iteratively through a greedy search. The best model is the one that minimizes the considered information criterion, measured with either Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC). BIC penalizes more complex models, compared with AIC.

In general, AIC is better in situations when a false negative finding would be considered more misleading than a false positive, and BIC is better in situations where a false positive is as misleading as, or more misleading than, a false negative. The BIC resists overfitting better than the AIC and is more consistent in fitting a true model. The BIC is used as the information criterion.

### Full linear model on all predictors

```{r}
full.model <- lm(FAA.F8F7 ~ ., data = dataF8F7)
summary(full.model)
```

```{r}
# This function computes the simplified anova from a linear model SST=SSR+SSE
# R^2 is related to anova decomp, as R^2=SSR / SSR +(n-p-1)*s^2
# R^2 measures the proportion of variation of the response variable  
# Y that is explained by the predictors through the regression (model fit)
# From https://bookdown.org/egarpor/PM-UC3M/lm-i-anova.html
simpleAnova <- function(object, ...) {
    
    # Compute anova table
    tab <- anova(object, ...)
    
    # Obtain number of predictors
    p <- nrow(tab) - 1
    
    # Add predictors row
    predictorsRow <- colSums(tab[1:p, 1:2])
    predictorsRow <- c(predictorsRow, predictorsRow[2] / predictorsRow[1])
    
    # F-quantities
    Fval <- predictorsRow[3] / tab[p + 1, 3]
    pval <- pf(Fval, df1 = p, df2 = tab$Df[p + 1], lower.tail = FALSE)
    predictorsRow <- c(predictorsRow, Fval, pval)
    
    # Simplified table
    tab <- rbind(predictorsRow, tab[p + 1, ])
    row.names(tab)[1] <- "Predictors"
    return(tab)
    
}
simpleAnova(full.model)
```

The adjusted $R^{2}=0.-0.01999$ is low. No predictors are significant. 

Model selection is performed with stepAIC, which performs a forward-backward search starting from the full model. This results in a candidate best model.
```{r}
modelBIC <- MASS::stepAIC(full.model, k = log(N)) # BIC -430.31
modelAIC <- MASS::stepAIC(full.model, trace = 0, k = 2) # AIC 
```

```{r}
summary(modelBIC)
```

The best model for predicting FAA is identified as one where the intercept is the only predictor.
```{r}
summary(modelAIC)
```

```{r}
# Comparison: same fits
car::compareCoefs(modelBIC, modelAIC)
```

```{r}
confint(modelBIC)
```
```{r}
confint(modelAIC)
```


```{r}
plot(dataF8F7$Age,dataF8F7$FAA.F8F7)
```

```{r}
# Test equality of variance for the predictor age. Looks good
leveneTest(dataF8F7$FAA.F8F7, Age)
```

